"""Training module."""

from {{ module_name }}.models import build_model

def train(
    X,
    y,
    model_params=None,
    cv=5, # alternatively can use train_test split as well
    eval_metrics=[]
):
    """Build model, then evaluate and train it.

    Args:
        X (DataFrame): Dependent feature matrix
        y (DataFrame): Target array

    Returns:
        model: Trained model
        evaulation_results: Evaluation results
    """
    # Perform CV
    skf = StratifiedKFold(cv)

    scores = []
    oof = np.zeros(len(y), dtype=int)
    models = []
    for fold, (tridx, validx) in enumerate(skf.split(X, y)):
        model_ = build_model(model_params)
        
        model_.fit(
            X[list(tridx)].to_numpy(),
            y[list(tridx)].to_numpy().ravel(),
        )
        models.append(model_)

        y_pred = model_.predict(X[list(validx)].to_numpy())
        oof[validx] = y_pred

        score = f1_score(y[list(validx)].to_numpy().ravel(), y_pred)
        scores.append(score)

        train_score = f1_score(y[list(tridx)].to_numpy().ravel(), model_.predict(X[list(tridx)].to_numpy()))

        print(f"Fold: {fold}, Valid F1: {score:.6f}, Train F1: {train_score:.6f}")

    # Evaluate on metrics
    cv_mean_qwk_score = np.mean(scores)
    cv_std_qwk_score = np.std(scores)
    oof_score = f1_score(y, oof)
    clf_report = classification_report(y, oof)

    evaluation_metrics = {
        "CV Mean F1 Score": cv_mean_qwk_score,
        "CV Std F1 Score": cv_std_qwk_score,
        "OOF F1 Score": oof_score,
        "OOF Classification Report": clf_report
    }

    return evaluation_metrics

    # Retrain model on full dataset

    # Or TODO: give an option  to make mean model of fold models
    model.fit(X.to_numpy(), y.to_numpy().ravel())

    # return {
    #     "model": model,
    #     "oof_raw": oof,
    #     "evaluation_metrics": evaluation_metrics,
    # }
